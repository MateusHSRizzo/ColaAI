import streamlit as st
import os
from langchain.memory import ConversationBufferMemory
from langchain_groq import ChatGroq
from langchain_openai import ChatOpenAI
from langchain.chains import create_retrieval_chain, create_history_aware_retriever
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# Importa as fun√ß√µes dos outros arquivos
from auth import pagina_login
from data_processing import atualizar_vetores, inicializar_retriever, carregar_documentos

# --- Constantes e Modelos de IA ---
CAMINHO_DOCUMENTOS = "dados_docs"
MODELOS_DISPONIVEIS = {
    'Groq (Limitado)': {'versao_api': ['openai/gpt-oss-120b'], 'chat': ChatGroq},
    'OpenAI (Premium)': {'versao_api': ['gpt-4o-mini'], 'chat': ChatOpenAI}
}

# --- Inicializa√ß√£o do Estado da Sess√£o ---
if 'logged_in' not in st.session_state: st.session_state.logged_in = False
if 'memoria' not in st.session_state: st.session_state.memoria = ConversationBufferMemory(return_messages=True, memory_key="chat_history")
if 'chain' not in st.session_state: st.session_state.chain = None
if 'retriever' not in st.session_state: st.session_state.retriever = None

# --- Fun√ß√µes da Interface (UI) ---
def pagina_chat():
    """Renderiza a p√°gina principal do chat."""
    st.title("Bem-vindo ao ColaAI üòà")
    st.write("Seu amiguinho na hora da prova.")
    st.divider()
    
    # Exibe o hist√≥rico da conversa
    for message in st.session_state.memoria.chat_memory.messages:
        with st.chat_message(message.type):
            st.markdown(message.content)
    
    if not st.session_state.chain:
        st.warning("‚ö†Ô∏è O modelo n√£o foi inicializado. Configure-o na barra lateral.")
        st.chat_input('Inicialize o modelo para come√ßar a conversar.', disabled=True)
        return
    
    if input_usuario := st.chat_input('Fa√ßa sua pergunta ao PlenoDoc...'):
        with st.chat_message("user"):
            st.markdown(input_usuario)
        
        with st.spinner("Analisando documentos e pensando..."):
            try:
                chat_history = st.session_state.memoria.load_memory_variables({})['chat_history']
                resposta = st.session_state.chain.invoke({"input": input_usuario, "chat_history": chat_history})
                
                st.session_state.memoria.save_context({"input": input_usuario}, {"output": resposta["answer"]})
                
                with st.chat_message("ai"):
                    st.markdown(resposta["answer"])
            except Exception as e:
                st.error(f"‚ùå Erro ao processar a consulta: {e}")

def painel_documentos():
    """Painel interativo para upload e gerenciamento de documentos."""
    st.subheader("Adicionar Novos Documentos")
    arquivos = st.file_uploader(
        'Arraste e solte arquivos aqui', 
        accept_multiple_files=True, 
        type=['pdf', 'csv', 'txt', 'docx'],
        label_visibility="collapsed"
    )
    if st.button("Processar Arquivos", use_container_width=True):
        if arquivos:
            caminhos_arquivos = []
            os.makedirs(CAMINHO_DOCUMENTOS, exist_ok=True)
            for arquivo in arquivos:
                caminho_salvar = os.path.join(CAMINHO_DOCUMENTOS, arquivo.name)
                with open(caminho_salvar, 'wb') as f: f.write(arquivo.getbuffer())
                caminhos_arquivos.append(caminho_salvar)
            with st.spinner("Atualizando base de conhecimento..."):
                documentos = carregar_documentos(caminhos_arquivos)
                atualizar_vetores(documentos)
                st.rerun()
        else: st.warning("Nenhum arquivo selecionado para processar.")

    st.divider()

    st.subheader("Documentos na Base")
    if not os.path.exists(CAMINHO_DOCUMENTOS) or not os.listdir(CAMINHO_DOCUMENTOS):
        st.info("Nenhum documento encontrado.")
    else:
        for nome_arquivo in os.listdir(CAMINHO_DOCUMENTOS):
            col1, col2 = st.columns([0.85, 0.15])
            with col1:
                st.text(nome_arquivo)
            with col2:
                # Bot√£o de remo√ß√£o com √≠cone de lixeira
                if st.button("üóëÔ∏è", key=f"remover_{nome_arquivo}", use_container_width=True, help=f"Remover {nome_arquivo}"):
                    caminho_arquivo = os.path.join(CAMINHO_DOCUMENTOS, nome_arquivo)
                    os.remove(caminho_arquivo)
                    with st.spinner(f"Removendo '{nome_arquivo}'..."):
                        documentos_restantes = carregar_documentos([os.path.join(CAMINHO_DOCUMENTOS, f) for f in os.listdir(CAMINHO_DOCUMENTOS)])
                        atualizar_vetores(documentos_restantes)
                        st.toast(f"'{nome_arquivo}' removido com sucesso.", icon="‚úÖ")
                        st.rerun()

def sidebar():
    """Renderiza a barra lateral de configura√ß√µes."""
    st.sidebar.header("Configura√ß√µes do ColaAI")
    
    tabs = st.sidebar.tabs(['Gerenciar Documentos', 'Sele√ß√£o de Modelo'])
    
    with tabs[0]:
        painel_documentos()
    
    with tabs[1]:
        st.subheader("Modelo de IA")
        selecao_provedor = st.selectbox('Provedor', MODELOS_DISPONIVEIS.keys(), label_visibility="collapsed")
        modelo = st.selectbox('Modelo', MODELOS_DISPONIVEIS[selecao_provedor]['versao_api'], label_visibility="collapsed")
        
        st.subheader("Chave de API")
        api_key = st.text_input(f'Chave da API para {selecao_provedor}', type='password', label_visibility="collapsed")
        
        if st.button('Inicializar PlenoDoc', use_container_width=True, type="primary"):
            if not api_key.strip():
                st.error('√â necess√°rio fornecer uma chave de API v√°lida.')
            else:
                inicializar_modelo(selecao_provedor, modelo, api_key.strip())
    
    # Bot√£o de Logout posicionado no final para melhor visualiza√ß√£o
    st.sidebar.divider()
    if st.sidebar.button("Logout", use_container_width=True):
        st.session_state.logged_in = False
        st.session_state.memoria.clear()
        st.session_state.chain = None
        st.session_state.retriever = None
        st.rerun()


def inicializar_modelo(selecao_provedor, modelo, api_key):
    """Inicializa o LLM e a cadeia de conversa√ß√£o RAG."""
    retriever = inicializar_retriever()
    if not retriever:
        st.error("A base de conhecimento (vetores) n√£o est√° pronta.")
        return

    try:
        llm = MODELOS_DISPONIVEIS[selecao_provedor]['chat'](model=modelo, api_key=api_key, temperature=0.3)
        prompt_historico = ChatPromptTemplate.from_messages([
            ("system", "Com base na conversa abaixo, gere uma pergunta de busca que possa ser entendida sem o hist√≥rico do chat."),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{input}"),
        ])
        retriever_chain = create_history_aware_retriever(llm, retriever, prompt_historico)
        prompt_resposta = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um consultor especialista chamado PlenoDoc. Sua miss√£o √© responder √†s perguntas do usu√°rio de forma detalhada e precisa.
REGRAS:
**1. PERSONA E IDENTIDADE:**
A partir de agora, voc√™ atuar√° como o **"ColaAI"**. Voc√™ √© um assistente de conhecimento inteligente, amig√°vel e prestativo. Sua personalidade √© a de um parceiro de estudos ou um colega experiente, sempre disposto a ajudar a entender um assunto em profundidade. Seu tom √© conversacional, mas preciso.

**2. OBJETIVO PRINCIPAL:**
Seu objetivo √© ajudar o usu√°rio a compreender e explorar os t√≥picos presentes nos documentos fornecidos. Voc√™ deve usar os documentos como a base principal da conversa, mas enriquecer as respostas com seu conhecimento geral para fornecer explica√ß√µes completas, exemplos pr√°ticos e conex√µes com outros assuntos relevantes.

**3. REGRAS DE OPERA√á√ÉO:**

* **REGRA 1: O CONTEXTO √â A BASE (MAS N√ÉO A JAULA):** A sua fonte prim√°ria de verdade e o ponto de partida para qualquer resposta √© o contexto dos documentos fornecidos. Sempre priorize a informa√ß√£o contida neles.

* **REGRA 2: ENRIQUE√áA E EXPANDA:** Diferente de um assistente restrito, voc√™ **deve** usar seu conhecimento pr√©vio para melhorar a resposta. Se o documento cita um termo t√©cnico, explique-o de forma simples. Se menciona um evento, forne√ßa o contexto hist√≥rico. Se apresenta uma f√≥rmula, d√™ um exemplo pr√°tico de seu uso. O objetivo √© entregar uma resposta mais completa e √∫til do que o documento sozinho poderia oferecer.

* **REGRA 3: O FILTRO DE RELEV√ÇNCIA (A REGRA DOS 70%):** Voc√™ deve manter o foco no universo tem√°tico dos documentos.
    * Se a pergunta do usu√°rio tiver uma **conex√£o substancial com o contexto** (aproximadamente 70% ou mais de sobreposi√ß√£o tem√°tica), responda-a generosamente, combinando as informa√ß√µes dos documentos com seu conhecimento geral.
    * Se a pergunta for **muito distante ou completamente fora do escopo** do material fornecido (ex: perguntar sobre culin√°ria quando o documento √© sobre programa√ß√£o), informe educadamente que o assunto foge do material de estudo atual, mas se coloque √† disposi√ß√£o para responder a perguntas relacionadas ao contexto.

* **REGRA 4: SEJA UM BOM CONVERSADOR:** Mantenha um di√°logo natural. Fa√ßa perguntas de esclarecimento se necess√°rio e use uma linguagem acess√≠vel, evitando jarg√µes sempre que poss√≠vel ou explicando-os quando inevit√°vel.
[CONTEXTO]
{context}
[/CONTEXTO]"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{input}"),
        ])
        document_chain = create_stuff_documents_chain(llm, prompt_resposta)
        st.session_state.chain = create_retrieval_chain(retriever_chain, document_chain)
        st.success(f"‚úÖ Modelo {modelo} inicializado com sucesso!")
    except Exception as e:
        st.error(f"‚ùå Falha ao inicializar o modelo: {e}")
        st.session_state.chain = None

# --- Fun√ß√£o Principal que Executa a Aplica√ß√£o ---
def main():
    if st.session_state.logged_in:
        sidebar()
        pagina_chat()
    else:
        pagina_login()
        
if __name__ == '__main__':

    main()
